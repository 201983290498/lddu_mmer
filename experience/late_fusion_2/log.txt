2025-02-19 07:07:28,819:INFO: Effective parameters:
2025-02-19 07:07:28,819:INFO:   <<< aligned: True
2025-02-19 07:07:28,819:INFO:   <<< audio_dim: 74
2025-02-19 07:07:28,819:INFO:   <<< audio_model: audio-base
2025-02-19 07:07:28,820:INFO:   <<< audio_num_hidden_layers: 3
2025-02-19 07:07:28,820:INFO:   <<< average: False
2025-02-19 07:07:28,820:INFO:   <<< batch_size: 64
2025-02-19 07:07:28,820:INFO:   <<< bert_model: bert-base
2025-02-19 07:07:28,820:INFO:   <<< bert_num_hidden_layers: 3
2025-02-19 07:07:28,820:INFO:   <<< cdl: 1.0
2025-02-19 07:07:28,820:INFO:   <<< cml: 0.3
2025-02-19 07:07:28,820:INFO:   <<< coef_lr: 0.1
2025-02-19 07:07:28,820:INFO:   <<< crl: 0.3
2025-02-19 07:07:28,820:INFO:   <<< cross_model: cross-base
2025-02-19 07:07:28,820:INFO:   <<< cross_num_hidden_layers: 3
2025-02-19 07:07:28,820:INFO:   <<< data_path: ./datasets/dataset1/aligned_501.pkl
2025-02-19 07:07:28,820:INFO:   <<< decoder_model: decoder-base
2025-02-19 07:07:28,820:INFO:   <<< decoder_num_hidden_layers: 1
2025-02-19 07:07:28,820:INFO:   <<< device: cuda:1
2025-02-19 07:07:28,820:INFO:   <<< do_test: False
2025-02-19 07:07:28,820:INFO:   <<< do_train: True
2025-02-19 07:07:28,820:INFO:   <<< epochs: 30
2025-02-19 07:07:28,820:INFO:   <<< final_loss: 1.0
2025-02-19 07:07:28,820:INFO:   <<< gradient_accumulation_steps: 1
2025-02-19 07:07:28,820:INFO:   <<< hidden_size: 256
2025-02-19 07:07:28,820:INFO:   <<< init_model: None
2025-02-19 07:07:28,820:INFO:   <<< kll: 0.0
2025-02-19 07:07:28,820:INFO:   <<< label_dim: 256
2025-02-19 07:07:28,820:INFO:   <<< latent_size: 128
2025-02-19 07:07:28,820:INFO:   <<< local_rank: 0
2025-02-19 07:07:28,820:INFO:   <<< lr: 0.0002
2025-02-19 07:07:28,820:INFO:   <<< lr_decay: 0.9
2025-02-19 07:07:28,820:INFO:   <<< max_frames: 60
2025-02-19 07:07:28,820:INFO:   <<< max_label: 6
2025-02-19 07:07:28,821:INFO:   <<< max_sequence: 60
2025-02-19 07:07:28,821:INFO:   <<< max_words: 60
2025-02-19 07:07:28,821:INFO:   <<< moco_queue: 8192
2025-02-19 07:07:28,821:INFO:   <<< n_display: 10
2025-02-19 07:07:28,821:INFO:   <<< n_gpu: 1
2025-02-19 07:07:28,821:INFO:   <<< num_classes: 6
2025-02-19 07:07:28,821:INFO:   <<< num_thread_reader: 1
2025-02-19 07:07:28,821:INFO:   <<< output_dir: ./experience/late_fusion_2
2025-02-19 07:07:28,821:INFO:   <<< pro_dim: 256
2025-02-19 07:07:28,821:INFO:   <<< rel: 0.0
2025-02-19 07:07:28,821:INFO:   <<< seed: 42
2025-02-19 07:07:28,821:INFO:   <<< temperature: 0.07
2025-02-19 07:07:28,821:INFO:   <<< text_dim: 768
2025-02-19 07:07:28,821:INFO:   <<< threshold: 0.21
2025-02-19 07:07:28,821:INFO:   <<< unaligned_data_path: ./datasets/MMSA/aligned_501.pkl
2025-02-19 07:07:28,821:INFO:   <<< video_dim: 35
2025-02-19 07:07:28,821:INFO:   <<< visual_model: visual-base
2025-02-19 07:07:28,821:INFO:   <<< visual_num_hidden_layers: 3
2025-02-19 07:07:28,821:INFO:   <<< warmup_proportion: 0.1
2025-02-19 07:07:28,821:INFO:   <<< world_size: 0
2025-02-19 07:07:28,821:INFO: device: cuda:1 n_gpu: 1
2025-02-19 07:07:28,821:INFO: loading archive file /data/huangjingwang/Article1_MultiModal/lddu/src/models/bert-base
2025-02-19 07:07:28,821:INFO: Model config {
  "attention_probs_dropout_prob": 0.3,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.3,
  "hidden_size": 256,
  "initializer_range": 0.02,
  "intermediate_size": 256,
  "max_position_embeddings": 60,
  "num_attention_heads": 8,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 300
}

2025-02-19 07:07:28,822:INFO: Weight doesn't exsits. /data/huangjingwang/Article1_MultiModal/lddu/src/models/bert-base/bert_pytorch_model.bin
2025-02-19 07:07:28,822:INFO: loading archive file /data/huangjingwang/Article1_MultiModal/lddu/src/models/visual-base
2025-02-19 07:07:28,822:INFO: Model config {
  "attention_probs_dropout_prob": 0.3,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.3,
  "hidden_size": 256,
  "initializer_range": 0.02,
  "intermediate_size": 256,
  "max_position_embeddings": 60,
  "num_attention_heads": 8,
  "num_hidden_layers": 1,
  "type_vocab_size": 2,
  "vocab_size": 35
}

2025-02-19 07:07:28,822:INFO: Weight doesn't exsits. /data/huangjingwang/Article1_MultiModal/lddu/src/models/visual-base/visual_pytorch_model.bin
2025-02-19 07:07:28,822:INFO: loading archive file /data/huangjingwang/Article1_MultiModal/lddu/src/models/audio-base
2025-02-19 07:07:28,822:INFO: Model config {
  "attention_probs_dropout_prob": 0.3,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.3,
  "hidden_size": 256,
  "initializer_range": 0.02,
  "intermediate_size": 256,
  "max_position_embeddings": 60,
  "num_attention_heads": 8,
  "num_hidden_layers": 1,
  "type_vocab_size": 2,
  "vocab_size": 74
}

2025-02-19 07:07:28,822:INFO: Weight doesn't exsits. /data/huangjingwang/Article1_MultiModal/lddu/src/models/audio-base/audio_model.bin
2025-02-19 07:07:28,822:INFO: loading archive file /data/huangjingwang/Article1_MultiModal/lddu/src/models/cross-base
2025-02-19 07:07:28,822:INFO: Model config {
  "attention_probs_dropout_prob": 0.3,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.3,
  "hidden_size": 256,
  "initializer_range": 0.02,
  "intermediate_size": 256,
  "max_position_embeddings": 240,
  "num_attention_heads": 8,
  "num_hidden_layers": 2,
  "type_vocab_size": 2,
  "vocab_size": 256
}

2025-02-19 07:07:28,822:INFO: Weight doesn't exsits. /data/huangjingwang/Article1_MultiModal/lddu/src/models/cross-base/cross_pytorch_model.bin
2025-02-19 07:07:28,822:INFO: loading archive file /data/huangjingwang/Article1_MultiModal/lddu/src/models/decoder-base
2025-02-19 07:07:28,823:INFO: Model config {
  "attention_probs_dropout_prob": 0.3,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.3,
  "hidden_size": 256,
  "initializer_range": 0.02,
  "intermediate_size": 256,
  "max_target_embeddings": 6,
  "num_attention_heads": 8,
  "num_decoder_layers": 1,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 6
}

2025-02-19 07:07:28,823:INFO: Weight doesn't exsits. /data/huangjingwang/Article1_MultiModal/lddu/src/models/decoder-base/decoder_pytorch_model.bin
2025-02-19 07:07:28,823:WARNING: Set bert_config.num_hidden_layers: 3.
2025-02-19 07:07:28,823:WARNING: Set bert_config.vocab_size: 768.
2025-02-19 07:07:29,054:WARNING: Set visual_config.num_hidden_layers: 3.
2025-02-19 07:07:29,054:WARNING: Set visual_config.vocab_size: 35.
2025-02-19 07:07:29,075:WARNING: Set audio_config.num_hidden_layers: 3.
2025-02-19 07:07:29,075:WARNING: Set audio_config.vocab_size: 74.
2025-02-19 07:07:29,450:WARNING: !!!!!!!!!!!!!! you start train aligned dataset
2025-02-19 08:06:48,662:INFO: Effective parameters:
2025-02-19 08:06:48,662:INFO:   <<< aligned: True
2025-02-19 08:06:48,662:INFO:   <<< audio_dim: 74
2025-02-19 08:06:48,662:INFO:   <<< audio_model: audio-base
2025-02-19 08:06:48,662:INFO:   <<< audio_num_hidden_layers: 3
2025-02-19 08:06:48,662:INFO:   <<< average: False
2025-02-19 08:06:48,662:INFO:   <<< batch_size: 64
2025-02-19 08:06:48,662:INFO:   <<< bert_model: bert-base
2025-02-19 08:06:48,662:INFO:   <<< bert_num_hidden_layers: 3
2025-02-19 08:06:48,662:INFO:   <<< cdl: 1.0
2025-02-19 08:06:48,662:INFO:   <<< cml: 0.3
2025-02-19 08:06:48,662:INFO:   <<< coef_lr: 0.1
2025-02-19 08:06:48,662:INFO:   <<< crl: 0.3
2025-02-19 08:06:48,662:INFO:   <<< cross_model: cross-base
2025-02-19 08:06:48,662:INFO:   <<< cross_num_hidden_layers: 3
2025-02-19 08:06:48,662:INFO:   <<< data_path: /data/huangjingwang/Article1_MultiModal/datasets/MMSA/aligned_501.pkl
2025-02-19 08:06:48,662:INFO:   <<< decoder_model: decoder-base
2025-02-19 08:06:48,662:INFO:   <<< decoder_num_hidden_layers: 1
2025-02-19 08:06:48,662:INFO:   <<< device: cuda:1
2025-02-19 08:06:48,662:INFO:   <<< do_test: False
2025-02-19 08:06:48,662:INFO:   <<< do_train: True
2025-02-19 08:06:48,662:INFO:   <<< epochs: 30
2025-02-19 08:06:48,662:INFO:   <<< final_loss: 1.0
2025-02-19 08:06:48,662:INFO:   <<< gradient_accumulation_steps: 1
2025-02-19 08:06:48,662:INFO:   <<< hidden_size: 256
2025-02-19 08:06:48,663:INFO:   <<< init_model: None
2025-02-19 08:06:48,663:INFO:   <<< kll: 0.0
2025-02-19 08:06:48,663:INFO:   <<< label_dim: 256
2025-02-19 08:06:48,663:INFO:   <<< latent_size: 128
2025-02-19 08:06:48,663:INFO:   <<< local_rank: 0
2025-02-19 08:06:48,663:INFO:   <<< lr: 0.0002
2025-02-19 08:06:48,663:INFO:   <<< lr_decay: 0.9
2025-02-19 08:06:48,663:INFO:   <<< max_frames: 60
2025-02-19 08:06:48,663:INFO:   <<< max_label: 6
2025-02-19 08:06:48,663:INFO:   <<< max_sequence: 60
2025-02-19 08:06:48,663:INFO:   <<< max_words: 60
2025-02-19 08:06:48,663:INFO:   <<< moco_queue: 8192
2025-02-19 08:06:48,663:INFO:   <<< n_display: 10
2025-02-19 08:06:48,663:INFO:   <<< n_gpu: 1
2025-02-19 08:06:48,663:INFO:   <<< num_classes: 6
2025-02-19 08:06:48,663:INFO:   <<< num_thread_reader: 1
2025-02-19 08:06:48,663:INFO:   <<< output_dir: ./experience/late_fusion_2
2025-02-19 08:06:48,663:INFO:   <<< pro_dim: 256
2025-02-19 08:06:48,663:INFO:   <<< rel: 0.0
2025-02-19 08:06:48,663:INFO:   <<< seed: 42
2025-02-19 08:06:48,663:INFO:   <<< temperature: 0.07
2025-02-19 08:06:48,663:INFO:   <<< text_dim: 768
2025-02-19 08:06:48,663:INFO:   <<< threshold: 0.21
2025-02-19 08:06:48,663:INFO:   <<< unaligned_data_path: ./datasets/MMSA/aligned_501.pkl
2025-02-19 08:06:48,663:INFO:   <<< video_dim: 35
2025-02-19 08:06:48,663:INFO:   <<< visual_model: visual-base
2025-02-19 08:06:48,663:INFO:   <<< visual_num_hidden_layers: 3
2025-02-19 08:06:48,663:INFO:   <<< warmup_proportion: 0.1
2025-02-19 08:06:48,663:INFO:   <<< world_size: 0
2025-02-19 08:06:48,663:INFO: device: cuda:1 n_gpu: 1
2025-02-19 08:06:48,663:INFO: loading archive file /data/huangjingwang/Article1_MultiModal/lddu/src/models/bert-base
2025-02-19 08:06:48,664:INFO: Model config {
  "attention_probs_dropout_prob": 0.3,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.3,
  "hidden_size": 256,
  "initializer_range": 0.02,
  "intermediate_size": 256,
  "max_position_embeddings": 60,
  "num_attention_heads": 8,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 300
}

2025-02-19 08:06:48,664:INFO: Weight doesn't exsits. /data/huangjingwang/Article1_MultiModal/lddu/src/models/bert-base/bert_pytorch_model.bin
2025-02-19 08:06:48,664:INFO: loading archive file /data/huangjingwang/Article1_MultiModal/lddu/src/models/visual-base
2025-02-19 08:06:48,664:INFO: Model config {
  "attention_probs_dropout_prob": 0.3,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.3,
  "hidden_size": 256,
  "initializer_range": 0.02,
  "intermediate_size": 256,
  "max_position_embeddings": 60,
  "num_attention_heads": 8,
  "num_hidden_layers": 1,
  "type_vocab_size": 2,
  "vocab_size": 35
}

2025-02-19 08:06:48,664:INFO: Weight doesn't exsits. /data/huangjingwang/Article1_MultiModal/lddu/src/models/visual-base/visual_pytorch_model.bin
2025-02-19 08:06:48,664:INFO: loading archive file /data/huangjingwang/Article1_MultiModal/lddu/src/models/audio-base
2025-02-19 08:06:48,664:INFO: Model config {
  "attention_probs_dropout_prob": 0.3,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.3,
  "hidden_size": 256,
  "initializer_range": 0.02,
  "intermediate_size": 256,
  "max_position_embeddings": 60,
  "num_attention_heads": 8,
  "num_hidden_layers": 1,
  "type_vocab_size": 2,
  "vocab_size": 74
}

2025-02-19 08:06:48,664:INFO: Weight doesn't exsits. /data/huangjingwang/Article1_MultiModal/lddu/src/models/audio-base/audio_model.bin
2025-02-19 08:06:48,665:INFO: loading archive file /data/huangjingwang/Article1_MultiModal/lddu/src/models/cross-base
2025-02-19 08:06:48,665:INFO: Model config {
  "attention_probs_dropout_prob": 0.3,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.3,
  "hidden_size": 256,
  "initializer_range": 0.02,
  "intermediate_size": 256,
  "max_position_embeddings": 240,
  "num_attention_heads": 8,
  "num_hidden_layers": 2,
  "type_vocab_size": 2,
  "vocab_size": 256
}

2025-02-19 08:06:48,665:INFO: Weight doesn't exsits. /data/huangjingwang/Article1_MultiModal/lddu/src/models/cross-base/cross_pytorch_model.bin
2025-02-19 08:06:48,665:INFO: loading archive file /data/huangjingwang/Article1_MultiModal/lddu/src/models/decoder-base
2025-02-19 08:06:48,665:INFO: Model config {
  "attention_probs_dropout_prob": 0.3,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.3,
  "hidden_size": 256,
  "initializer_range": 0.02,
  "intermediate_size": 256,
  "max_target_embeddings": 6,
  "num_attention_heads": 8,
  "num_decoder_layers": 1,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 6
}

2025-02-19 08:06:48,665:INFO: Weight doesn't exsits. /data/huangjingwang/Article1_MultiModal/lddu/src/models/decoder-base/decoder_pytorch_model.bin
2025-02-19 08:06:48,665:WARNING: Set bert_config.num_hidden_layers: 3.
2025-02-19 08:06:48,665:WARNING: Set bert_config.vocab_size: 768.
2025-02-19 08:06:48,725:WARNING: Set visual_config.num_hidden_layers: 3.
2025-02-19 08:06:48,725:WARNING: Set visual_config.vocab_size: 35.
2025-02-19 08:06:48,745:WARNING: Set audio_config.num_hidden_layers: 3.
2025-02-19 08:06:48,745:WARNING: Set audio_config.vocab_size: 74.
2025-02-19 08:06:49,029:WARNING: !!!!!!!!!!!!!! you start train aligned dataset
2025-02-19 08:07:14,837:INFO: ***** Running training *****
2025-02-19 08:07:14,837:INFO:   Num examples = 16326
2025-02-19 08:07:14,837:INFO:   Batch size = 64
2025-02-19 08:07:14,837:INFO:   Num steps = 7680
2025-02-19 08:08:08,272:INFO: Epoch 1/30 Finished, Train Loss: 8.499125, Train_micro_f1: 0.466192, Train_micro_precision: 0.775840, Train_micro_recall: 0.333206,  Train_acc: 0.353400, train_gap: 0.451023
2025-02-19 08:08:08,273:INFO: ***** Running testing *****
2025-02-19 08:08:08,273:INFO:   Num examples = 4659
2025-02-19 08:08:08,273:INFO:   Batch_size = 64
2025-02-19 08:08:13,294:INFO: ----- micro_f1: 0.540860, micro_precision: 0.721959, micro_recall: 0.432397,  acc: 0.444800, test_gap: 0.572378, threshold: 0.210000
2025-02-19 08:08:13,379:INFO: Model saved to ./experience/late_fusion_2/pytorch_model_0.bin.
2025-02-19 08:08:13,380:INFO: The best model is: ./experience/late_fusion_2/pytorch_model_0.bin., the f1 is: 0.5409
2025-02-19 08:09:03,373:INFO: Epoch 2/30 Finished, Train Loss: 7.423217, Train_micro_f1: 0.542644, Train_micro_precision: 0.724183, Train_micro_recall: 0.433879,  Train_acc: 0.447400, train_gap: 0.573370
2025-02-19 08:09:03,373:INFO: ***** Running testing *****
2025-02-19 08:09:03,373:INFO:   Num examples = 4659
2025-02-19 08:09:03,373:INFO:   Batch_size = 64
2025-02-19 08:09:08,368:INFO: ----- micro_f1: 0.543594, micro_precision: 0.709163, micro_recall: 0.440703,  acc: 0.442000, test_gap: 0.591653, threshold: 0.210000
2025-02-19 08:09:08,448:INFO: Model saved to ./experience/late_fusion_2/pytorch_model_1.bin.
2025-02-19 08:09:08,457:INFO: The best model is: ./experience/late_fusion_2/pytorch_model_1.bin., the f1 is: 0.5436
2025-02-19 08:09:58,495:INFO: Epoch 3/30 Finished, Train Loss: 6.938740, Train_micro_f1: 0.547901, Train_micro_precision: 0.731945, Train_micro_recall: 0.437815,  Train_acc: 0.452800, train_gap: 0.590832
2025-02-19 08:09:58,495:INFO: ***** Running testing *****
2025-02-19 08:09:58,495:INFO:   Num examples = 4659
2025-02-19 08:09:58,495:INFO:   Batch_size = 64
2025-02-19 08:10:03,661:INFO: ----- micro_f1: 0.537730, micro_precision: 0.758768, micro_recall: 0.416421,  acc: 0.446500, test_gap: 0.598703, threshold: 0.210000
2025-02-19 08:10:03,661:INFO: The best model is: ./experience/late_fusion_2/pytorch_model_1.bin., the f1 is: 0.5436
2025-02-19 08:10:53,341:INFO: Epoch 4/30 Finished, Train Loss: 6.913172, Train_micro_f1: 0.554278, Train_micro_precision: 0.741848, Train_micro_recall: 0.442417,  Train_acc: 0.458800, train_gap: 0.605616
2025-02-19 08:10:53,341:INFO: ***** Running testing *****
2025-02-19 08:10:53,341:INFO:   Num examples = 4659
2025-02-19 08:10:53,341:INFO:   Batch_size = 64
2025-02-19 08:10:58,487:INFO: ----- micro_f1: 0.535279, micro_precision: 0.776619, micro_recall: 0.408373,  acc: 0.423200, test_gap: 0.605284, threshold: 0.210000
2025-02-19 08:10:58,488:INFO: The best model is: ./experience/late_fusion_2/pytorch_model_1.bin., the f1 is: 0.5436
2025-02-19 08:11:48,565:INFO: Epoch 5/30 Finished, Train Loss: 6.895805, Train_micro_f1: 0.562914, Train_micro_precision: 0.751662, Train_micro_recall: 0.449933,  Train_acc: 0.464700, train_gap: 0.618410
2025-02-19 08:11:48,566:INFO: ***** Running testing *****
2025-02-19 08:11:48,566:INFO:   Num examples = 4659
2025-02-19 08:11:48,566:INFO:   Batch_size = 64
2025-02-19 08:11:54,002:INFO: ----- micro_f1: 0.558429, micro_precision: 0.716430, micro_recall: 0.457526,  acc: 0.458300, test_gap: 0.603202, threshold: 0.210000
2025-02-19 08:11:54,083:INFO: Model saved to ./experience/late_fusion_2/pytorch_model_4.bin.
2025-02-19 08:11:54,092:INFO: The best model is: ./experience/late_fusion_2/pytorch_model_4.bin., the f1 is: 0.5584
2025-02-19 08:12:43,896:INFO: Epoch 6/30 Finished, Train Loss: 6.888519, Train_micro_f1: 0.570829, Train_micro_precision: 0.757773, Train_micro_recall: 0.457871,  Train_acc: 0.473000, train_gap: 0.629936
2025-02-19 08:12:43,896:INFO: ***** Running testing *****
2025-02-19 08:12:43,896:INFO:   Num examples = 4659
2025-02-19 08:12:43,897:INFO:   Batch_size = 64
2025-02-19 08:12:49,107:INFO: ----- micro_f1: 0.542114, micro_precision: 0.713270, micro_recall: 0.437203,  acc: 0.443600, test_gap: 0.580818, threshold: 0.210000
2025-02-19 08:12:49,107:INFO: The best model is: ./experience/late_fusion_2/pytorch_model_4.bin., the f1 is: 0.5584
2025-02-19 08:13:38,954:INFO: Epoch 7/30 Finished, Train Loss: 6.875125, Train_micro_f1: 0.575935, Train_micro_precision: 0.765669, Train_micro_recall: 0.461559,  Train_acc: 0.474900, train_gap: 0.644443
2025-02-19 08:13:38,954:INFO: ***** Running testing *****
2025-02-19 08:13:38,954:INFO:   Num examples = 4659
2025-02-19 08:13:38,954:INFO:   Batch_size = 64
2025-02-19 08:13:44,257:INFO: ----- micro_f1: 0.573476, micro_precision: 0.701580, micro_recall: 0.484931,  acc: 0.475600, test_gap: 0.620731, threshold: 0.210000
2025-02-19 08:13:44,339:INFO: Model saved to ./experience/late_fusion_2/pytorch_model_6.bin.
2025-02-19 08:13:44,349:INFO: The best model is: ./experience/late_fusion_2/pytorch_model_6.bin., the f1 is: 0.5735
2025-02-19 08:14:34,360:INFO: Epoch 8/30 Finished, Train Loss: 6.863537, Train_micro_f1: 0.586198, Train_micro_precision: 0.774725, Train_micro_recall: 0.471468,  Train_acc: 0.483900, train_gap: 0.657109
2025-02-19 08:14:34,360:INFO: ***** Running testing *****
2025-02-19 08:14:34,360:INFO:   Num examples = 4659
2025-02-19 08:14:34,360:INFO:   Batch_size = 64
2025-02-19 08:14:39,628:INFO: ----- micro_f1: 0.585041, micro_precision: 0.672196, micro_recall: 0.517892,  acc: 0.491900, test_gap: 0.623526, threshold: 0.210000
2025-02-19 08:14:39,709:INFO: Model saved to ./experience/late_fusion_2/pytorch_model_7.bin.
2025-02-19 08:14:39,718:INFO: The best model is: ./experience/late_fusion_2/pytorch_model_7.bin., the f1 is: 0.5850
2025-02-19 08:15:30,997:INFO: Epoch 9/30 Finished, Train Loss: 6.853517, Train_micro_f1: 0.593867, Train_micro_precision: 0.779230, Train_micro_recall: 0.479745,  Train_acc: 0.490200, train_gap: 0.669195
2025-02-19 08:15:30,997:INFO: ***** Running testing *****
2025-02-19 08:15:30,997:INFO:   Num examples = 4659
2025-02-19 08:15:30,997:INFO:   Batch_size = 64
2025-02-19 08:15:36,299:INFO: ----- micro_f1: 0.579573, micro_precision: 0.696998, micro_recall: 0.496009,  acc: 0.485800, test_gap: 0.619119, threshold: 0.210000
2025-02-19 08:15:36,299:INFO: The best model is: ./experience/late_fusion_2/pytorch_model_7.bin., the f1 is: 0.5850
2025-02-19 08:16:26,301:INFO: Epoch 10/30 Finished, Train Loss: 6.841694, Train_micro_f1: 0.603094, Train_micro_precision: 0.786858, Train_micro_recall: 0.488913,  Train_acc: 0.497400, train_gap: 0.682678
2025-02-19 08:16:26,302:INFO: ***** Running testing *****
2025-02-19 08:16:26,302:INFO:   Num examples = 4659
2025-02-19 08:16:26,302:INFO:   Batch_size = 64
2025-02-19 08:16:31,627:INFO: ----- micro_f1: 0.555729, micro_precision: 0.730964, micro_recall: 0.448266,  acc: 0.456000, test_gap: 0.590745, threshold: 0.210000
2025-02-19 08:16:31,628:INFO: The best model is: ./experience/late_fusion_2/pytorch_model_7.bin., the f1 is: 0.5850
2025-02-19 08:17:22,026:INFO: Epoch 11/30 Finished, Train Loss: 6.829994, Train_micro_f1: 0.612063, Train_micro_precision: 0.791721, Train_micro_recall: 0.498862,  Train_acc: 0.504600, train_gap: 0.697496
2025-02-19 08:17:22,027:INFO: ***** Running testing *****
2025-02-19 08:17:22,027:INFO:   Num examples = 4659
2025-02-19 08:17:22,027:INFO:   Batch_size = 64
2025-02-19 08:17:27,424:INFO: ----- micro_f1: 0.562011, micro_precision: 0.715166, micro_recall: 0.462883,  acc: 0.457900, test_gap: 0.608601, threshold: 0.210000
2025-02-19 08:17:27,424:INFO: The best model is: ./experience/late_fusion_2/pytorch_model_7.bin., the f1 is: 0.5850
2025-02-19 08:18:17,427:INFO: Epoch 12/30 Finished, Train Loss: 6.815589, Train_micro_f1: 0.625888, Train_micro_precision: 0.803587, Train_micro_recall: 0.512548,  Train_acc: 0.516100, train_gap: 0.711973
2025-02-19 08:18:17,427:INFO: ***** Running testing *****
2025-02-19 08:18:17,428:INFO:   Num examples = 4659
2025-02-19 08:18:17,428:INFO:   Batch_size = 64
2025-02-19 08:18:22,929:INFO: ----- micro_f1: 0.563399, micro_precision: 0.677725, micro_recall: 0.482077,  acc: 0.457300, test_gap: 0.605547, threshold: 0.210000
2025-02-19 08:18:22,929:INFO: The best model is: ./experience/late_fusion_2/pytorch_model_7.bin., the f1 is: 0.5850
2025-02-19 08:19:14,027:INFO: Epoch 13/30 Finished, Train Loss: 6.802966, Train_micro_f1: 0.633811, Train_micro_precision: 0.808627, Train_micro_recall: 0.521145,  Train_acc: 0.521400, train_gap: 0.725066
2025-02-19 08:19:14,027:INFO: ***** Running testing *****
2025-02-19 08:19:14,027:INFO:   Num examples = 4659
2025-02-19 08:19:14,027:INFO:   Batch_size = 64
2025-02-19 08:19:19,631:INFO: ----- micro_f1: 0.550577, micro_precision: 0.693049, micro_recall: 0.456694,  acc: 0.445600, test_gap: 0.581802, threshold: 0.210000
2025-02-19 08:19:19,632:INFO: The best model is: ./experience/late_fusion_2/pytorch_model_7.bin., the f1 is: 0.5850
2025-02-19 08:19:22,444:INFO: Final test results: f1 0.585041,	p 0.672196,	r 0.517892,	acc 0.491900
